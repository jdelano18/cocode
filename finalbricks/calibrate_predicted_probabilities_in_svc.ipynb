{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Calibrate Predicted Probabilities In SVC\"\n", "description: \"\"\n", "tags: machine_learning, support_vector_machines\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tCalibrate Predicted Probabilities In SVC\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["SVC's use of a hyperplane to create decision regions do not naturally output a probability estimate that an observation is a member of a certain class. However, we can in fact output calibrated class probabilities with a few caveats. In an SVC, Platt scaling can be used, wherein first the SVC is trained, then a separate cross-validated logistic regression is trained to map the SVC outputs into probabilities:\n", "\n", "$$P(y=1 \\mid x)={\\frac {1}{1+e^{(A*f(x)+B)}}}$$\n", "\n", "where $A$ and $B$ are parameter vectors and $f$ is the $i$th observation's signed distance from the hyperplane. When we have more than two classes, an extension of Platt scaling is used.\n", "\n", "In scikit-learn, the predicted probabilities must be generated when the model is being trained. This can be done by setting `SVC`'s `probability` to `True`. After the model is trained, we can output the estimated probabilities for each class using `predict_proba`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Load libraries\n", "from sklearn.svm import SVC\n", "from sklearn import datasets\n", "from sklearn.preprocessing import StandardScaler\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Iris Flower Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Load data\n", "iris = datasets.load_iris()\n", "X = iris.data\n", "y = iris.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Standardize Features"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Standarize features\n", "scaler = StandardScaler()\n", "X_std = scaler.fit_transform(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Support Vector Classifier"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create support vector classifier object\n", "svc = SVC(kernel='linear', probability=True, random_state=0)\n", "\n", "# Train classifier\n", "model = svc.fit(X_std, y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create Previously Unseen Observation"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create new observation\n", "new_observation = [[.4, .4, .4, .4]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View Predicted Probabilities"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[ 0.00588822,  0.96874828,  0.0253635 ]])"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["# View predicted probabilities\n", "model.predict_proba(new_observation)"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [conda root]", "language": "python", "name": "conda-root-py"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.3"}}, "nbformat": 4, "nbformat_minor": 1}