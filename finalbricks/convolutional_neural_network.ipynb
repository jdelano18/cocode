{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Convolutional Neural Network\"\n", "description: \"\"\n", "tags: deep_learning, keras\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tConvolutional Neural Network\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["import numpy as np\n", "from keras.datasets import mnist\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Flatten\n", "from keras.layers.convolutional import Conv2D, MaxPooling2D\n", "from keras.utils import np_utils\n", "from keras import backend as K \n", "\n", "# Set that the color channel value will be first\n", "K.set_image_data_format('channels_first')\n", "\n", "# Set seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load MNIST Image Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Set image information\n", "channels = 1\n", "height = 28\n", "width = 28\n", "\n", "# Load data and target from MNIST data\n", "(train_data, train_target), (test_data, test_target) = mnist.load_data()\n", "\n", "# Reshape training image data into features\n", "train_data = train_data.reshape(train_data.shape[0], channels, height, width)\n", "\n", "# Reshape test image data into features\n", "test_data = test_data.reshape(test_data.shape[0], channels, height, width)\n", "\n", "# Rescale pixel intensity to between 0 and 1\n", "train_features = train_data / 255\n", "test_features = test_data / 255\n", "\n", "# One-hot encode target\n", "train_target = np_utils.to_categorical(train_target)\n", "test_target = np_utils.to_categorical(test_target)\n", "number_of_classes = test_target.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create Convolutional Neural Network Architecture\n", "\n", "Convolutional neural networks (also called ConvNets) are a popular type of network that has proven very effective at computer vision (e.g. recognizing cats, dogs, planes, and even hot dogs). It is completely possible to use feedforward neural networks on images, where each pixel is a feature. However, when doing so we run into two major problems. \n", "\n", "First, a feedforward neural networks do not take into account the spatial structure of the pixels. For example, in a 10x10 pixel image we might convert it into a vector of 100 pixel features, and in this case feedforward would consider the first feature (e.g. pixel value) to have the same relationship with the 10th feature as the 11th feature. However, in reality the 10th feature represents a pixel on the far side of the image as the first feature, while the 11th feature represents the pixel immediately below the first pixel. \n", "\n", "Second, and relatedly, feedforward neural networks learn global relationships in the features instead of local patterns. In more practical terms, this means that feedforward neural networks are not able to detect an object regardless of where it appears in an image. For example, imagine we are training a neural network to recognize faces, these faces might appear anywhere in the image from the upper right to the middle to the lower left. The power of convolutional neural networks is their ability handle both of these issues (and others)."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Start neural network\n", "network = Sequential()\n", "\n", "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n", "network.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(channels, width, height), activation='relu'))\n", "\n", "# Add max pooling layer with a 2x2 window\n", "network.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "# Add dropout layer\n", "network.add(Dropout(0.5))\n", "\n", "# Add layer to flatten input\n", "network.add(Flatten())\n", "\n", "# # Add fully connected layer of 128 units with a ReLU activation function\n", "network.add(Dense(128, activation='relu'))\n", "\n", "# Add dropout layer\n", "network.add(Dropout(0.5))\n", "\n", "# Add fully connected layer with a softmax activation function\n", "network.add(Dense(number_of_classes, activation='softmax'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compile Convolutional Neural Network"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='categorical_crossentropy', # Cross-entropy\n", "                optimizer='rmsprop', # Root Mean Square Propagation\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Convolutional Neural Network"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["<keras.callbacks.History at 0x103f9b8d0>"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["# Train neural network\n", "network.fit(train_features, # Features\n", "            train_target, # Target\n", "            epochs=2, # Number of epochs\n", "            verbose=0, # Don't print description after each epoch\n", "            batch_size=1000, # Number of observations per batch\n", "            validation_data=(test_features, test_target)) # Data for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}