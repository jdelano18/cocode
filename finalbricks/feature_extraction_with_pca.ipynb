{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Feature Extraction With PCA\"\n", "description: \"\"\n", "tags: machine_learning, feature_engineering\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tFeature Extraction With PCA\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["[Principle Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) is a common feature extraction method in data science. Technically, PCA finds the eigenvectors of a covariance matrix with the highest eigenvalues and then uses those to project the data into a new subspace of equal or less dimensions. Practically, PCA converts a matrix of `n` features into a new dataset of (hopefully) less than `n` features. That is, it reduces the number of features by constructing a new, smaller number variables which capture a signficant portion of the information found in the original features. However, the goal of this tutorial is not to explain the concept of PCA, that is done very well elsewhere, but rather to demonstrate PCA in action."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Import packages\n", "import numpy as np\n", "from sklearn import decomposition, datasets\n", "from sklearn.preprocessing import StandardScaler"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Load Features"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Load the breast cancer dataset\n", "dataset = datasets.load_breast_cancer()\n", "\n", "# Load the features\n", "X = dataset.data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that original data contains 569 observations and 30 features."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": ["(569, 30)"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["# View the shape of the dataset\n", "X.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here is what the data looks like."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[  1.79900000e+01,   1.03800000e+01,   1.22800000e+02, ...,\n", "          2.65400000e-01,   4.60100000e-01,   1.18900000e-01],\n", "       [  2.05700000e+01,   1.77700000e+01,   1.32900000e+02, ...,\n", "          1.86000000e-01,   2.75000000e-01,   8.90200000e-02],\n", "       [  1.96900000e+01,   2.12500000e+01,   1.30000000e+02, ...,\n", "          2.43000000e-01,   3.61300000e-01,   8.75800000e-02],\n", "       ..., \n", "       [  1.66000000e+01,   2.80800000e+01,   1.08300000e+02, ...,\n", "          1.41800000e-01,   2.21800000e-01,   7.82000000e-02],\n", "       [  2.06000000e+01,   2.93300000e+01,   1.40100000e+02, ...,\n", "          2.65000000e-01,   4.08700000e-01,   1.24000000e-01],\n", "       [  7.76000000e+00,   2.45400000e+01,   4.79200000e+01, ...,\n", "          0.00000000e+00,   2.87100000e-01,   7.03900000e-02]])"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# View the data\n", "X"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Standardize Features"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create a scaler object\n", "sc = StandardScaler()\n", "\n", "# Fit the scaler to the features and transform\n", "X_std = sc.fit_transform(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conduct PCA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that PCA contains a parameter, the number of components. This is the number of output features and will need to be tuned."]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create a pca object with the 2 components as a parameter\n", "pca = decomposition.PCA(n_components=2)\n", "\n", "# Fit the PCA and transform the data\n", "X_std_pca = pca.fit_transform(X_std)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View New Features "]}, {"cell_type": "markdown", "metadata": {}, "source": ["After the PCA, the new data has been reduced to two features, with the same number of rows as the original feature."]}, {"cell_type": "code", "execution_count": 7, "metadata": {"scrolled": true}, "outputs": [{"data": {"text/plain": ["(569, 2)"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["# View the new feature data's shape\n", "X_std_pca.shape"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[  9.19283683,   1.94858307],\n", "       [  2.3878018 ,  -3.76817174],\n", "       [  5.73389628,  -1.0751738 ],\n", "       ..., \n", "       [  1.25617928,  -1.90229671],\n", "       [ 10.37479406,   1.67201011],\n", "       [ -5.4752433 ,  -0.67063679]])"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["# View the new feature data\n", "X_std_pca"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 1}