{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Feedforward Neural Network For Binary Classification\"\n", "description: \"\"\n", "tags: deep_learning, keras\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tFeedforward Neural Network For Binary Classification\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["# Load libraries\n", "import numpy as np\n", "from keras.datasets import imdb\n", "from keras.preprocessing.text import Tokenizer\n", "from keras import models\n", "from keras import layers\n", "\n", "# Set random seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Movie Review Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Set the number of features we want\n", "number_of_features = 1000\n", "\n", "# Load data and target vector from movie review data\n", "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n", "\n", "# Convert movie review data to one-hot encoded feature matrix\n", "tokenizer = Tokenizer(num_words=number_of_features)\n", "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n", "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Construct Neural Network Architecture"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Because this is a binary classification problem, one common choice is to use the sigmoid activation function in a one-unit output layer."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Start neural network\n", "network = models.Sequential()\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu'))\n", "\n", "# Add fully connected layer with a sigmoid activation function\n", "network.add(layers.Dense(units=1, activation='sigmoid'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compile Feedforward Neural Network"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='binary_crossentropy', # Cross-entropy\n", "                optimizer='rmsprop', # Root Mean Square Propagation\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Feedforward Neural Network\n", "\n", "In Keras, we train our neural network using the `fit` method. There are six significant parameters to define. The first two parameters are the features and target vector of the training data. \n", "\n", "The `epochs` parameter defines how many epochs to use when training the data. `verbose` determines how much information is outputted during the training process, with `0` being no out, `1` outputting a progress bar, and `2` one log line per epoch. `batch_size` sets the number of observations to propagate through the network before updating the parameters.\n", "\n", "Finally, we held out a test set of data to use to evaluate the model. These test features and test target vector can be arguments of the `validation_data`, which will use them for evaluation. Alternatively, we could have used `validation_split` to define what fraction of the training data we want to hold out for evaluation.\n", "\n", "In scikit-learn `fit` method returned a trained model, however in Keras the `fit` method returns a `History` object containing the loss values and performance metrics at each epoch."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Train on 25000 samples, validate on 25000 samples\n", "Epoch 1/3\n", "25000/25000 [==============================] - 2s - loss: 0.4215 - acc: 0.8102 - val_loss: 0.3385 - val_acc: 0.8558\n", "Epoch 2/3\n", "25000/25000 [==============================] - 1s - loss: 0.3241 - acc: 0.8646 - val_loss: 0.3261 - val_acc: 0.8626\n", "Epoch 3/3\n", "25000/25000 [==============================] - 2s - loss: 0.3120 - acc: 0.8700 - val_loss: 0.3268 - val_acc: 0.8593\n"]}], "source": ["# Train neural network\n", "history = network.fit(train_features, # Features\n", "                      train_target, # Target vector\n", "                      epochs=3, # Number of epochs\n", "                      verbose=1, # Print description after each epoch\n", "                      batch_size=100, # Number of observations per batch\n", "                      validation_data=(test_features, test_target)) # Data for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}