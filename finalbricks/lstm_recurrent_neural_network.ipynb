{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"LSTM Recurrent Neural Network\"\n", "description: \"\"\n", "tags: deep_learning, keras\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tLSTM Recurrent Neural Network\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Oftentimes we have text data that we want to classify. While it is possible to use a type of convolutional network, we are going to focus on a more popular option: the recurrent neural network. The key feature of recurrent neural networks is that information loops back in the network. This gives recurrent neural networks a type of memory it can use to better understand sequential data. A popular choice type of recurrent neural network is the long short-term memory (LSTM) network which allows for information to loop backwards in the network."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["# Load libraries\n", "import numpy as np\n", "from keras.datasets import imdb\n", "from keras.preprocessing import sequence\n", "from keras import models\n", "from keras import layers\n", "\n", "# Set random seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Dataset On Movie Review Text"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Set the number of features we want\n", "number_of_features = 1000\n", "\n", "# Load data and target vector from movie review data\n", "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n", "\n", "# Use padding or truncation to make each observation have 400 features\n", "train_features = sequence.pad_sequences(train_data, maxlen=400)\n", "test_features = sequence.pad_sequences(test_data, maxlen=400)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View First Observation's Raw Data"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"]}], "source": ["# View first observation\n", "print(train_data[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View First Observation's Feature Data"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n", "         0,   0,   0,   1,  89,  27,   2,   2,  17, 199, 132,   5,   2,\n", "        16,   2,  24,   8, 760,   4,   2,   7,   4,  22,   2,   2,  16,\n", "         2,  17,   2,   7,   2,   2,   9,   4,   2,   8,  14, 991,  13,\n", "       877,  38,  19,  27, 239,  13, 100, 235,  61, 483,   2,   4,   7,\n", "         4,  20, 131,   2,  72,   8,  14, 251,  27,   2,   7, 308,  16,\n", "       735,   2,  17,  29, 144,  28,  77,   2,  18,  12], dtype=int32)"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# View first observation\n", "test_features[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create LSTM Neural Network Architecture"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Start neural network\n", "network = models.Sequential()\n", "\n", "# Add an embedding layer\n", "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n", "\n", "# Add a long short-term memory layer with 128 units\n", "network.add(layers.LSTM(units=128))\n", "\n", "# Add fully connected layer with a sigmoid activation function\n", "network.add(layers.Dense(units=1, activation='sigmoid'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compule LSTM Neural Network Architecture"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='binary_crossentropy', # Cross-entropy\n", "                optimizer='Adam', # Adam optimization\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train LSTM Neural Network Architecture"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# Train neural network\n", "history = network.fit(train_features, # Features\n", "                      train_target, # Target\n", "                      epochs=3, # Number of epochs\n", "                      verbose=0, # Do not print description after each epoch\n", "                      batch_size=1000, # Number of observations per batch\n", "                      validation_data=(test_features, test_target)) # Data for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}