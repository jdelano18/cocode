{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Neural Network Early Stopping\"\n", "description: \"\"\n", "tags: deep_learning, keras\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tNeural Network Early Stopping\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["# Load libraries\n", "import numpy as np\n", "from keras.datasets import imdb\n", "from keras.preprocessing.text import Tokenizer\n", "from keras import models\n", "from keras import layers\n", "from keras.callbacks import EarlyStopping, ModelCheckpoint\n", "\n", "# Set random seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Movie Review Text Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Set the number of features we want\n", "number_of_features = 1000\n", "\n", "# Load data and target vector from movie review data\n", "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n", "\n", "# Convert movie review data to a one-hot encoded feature matrix\n", "tokenizer = Tokenizer(num_words=number_of_features)\n", "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n", "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create Neural Network Architecture"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Start neural network\n", "network = models.Sequential()\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu'))\n", "\n", "# Add fully connected layer with a sigmoid activation function\n", "network.add(layers.Dense(units=1, activation='sigmoid'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compile Neural Network"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='binary_crossentropy', # Cross-entropy\n", "                optimizer='rmsprop', # Root Mean Square Propagation\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Setup Early Stopping\n", "\n", "In Keras, we can implement early stopping as a callback function. Callbacks are functions that can be applied at certain stages of the training process, such as at the end of each epoch. Specifically, in our solution, we included `EarlyStopping(monitor='val_loss', patience=2)` to define that we wanted to monitor the test (validation) loss at each epoch and after the test loss has not improved after two epochs, training is interrupted. However, since we set `patience=2`, we won't get the best model, but the model two epochs after the best model. Therefore, optionally, we can include a second operation, `ModelCheckpoint` which saves the model to a file after every checkpoint (which can be useful in case a multi-day training session is interrupted for some reason. Helpful for us, if we set `save_best_only=True` then `ModelCheckpoint` will only save the best model."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Set callback functions to early stop training and save the best model so far\n", "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n", "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Neural Network"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Train neural network\n", "history = network.fit(train_features, # Features\n", "                      train_target, # Target vector\n", "                      epochs=20, # Number of epochs\n", "                      callbacks=callbacks, # Early stopping\n", "                      verbose=0, # Print description after each epoch\n", "                      batch_size=100, # Number of observations per batch\n", "                      validation_data=(test_features, test_target)) # Data for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}