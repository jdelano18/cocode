{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["---\n", "title: \"Support Vector Classifier\"\n", "description: \"\"\n", "tags: machine_learning, support_vector_machines\n", "URL: https://github.com/chrisalbon/notes\n", "Licence: \n", "Creator: \n", "Meta: \n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": [" <div>\n    \t<img src=\"./coco.png\" style=\"float: left;height: 55px\">\n    \t<div style=\"height: 75px;text-align: center; padding-top:5px\">\n        <h1>\n      \tSupport Vector Classifier\n        </h1>\n        <p></p>\n    \t</div>\n\t\t</div> "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a alt=\"Support Vector Classifier\" href=\"https://machinelearningflashcards.com\">\n", "    <img src=\"/images/machine_learning_flashcards/Support_Vector_Classifier_print.png\" class=\"flashcard center-block\">\n", "</a>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There is a balance between SVC maximizing the margin of the hyperplane and minimizing the misclassification. In SVC, the later is controlled with the hyperparameter $C$, the penalty imposed on errors. C is a parameter of the SVC learner and is the penalty for misclassifying a data point. When C is small, the classifier is okay with misclassified data points (high bias but low variance). When C is large, the classifier is heavily penalized for misclassified data and therefore bends over backwards avoid any misclassified data points (low bias but high variance).\n", "\n", "In scikit-learn, $C$ is determined by the parameter `C` and defaults to `C=1.0`. We should treat $C$ has a hyperparameter of our learning algorithm which we tune using model selection techniques."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Load libraries\n", "from sklearn.svm import LinearSVC\n", "from sklearn import datasets\n", "from sklearn.preprocessing import StandardScaler\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Iris Flower Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Load feature and target data\n", "iris = datasets.load_iris()\n", "X = iris.data\n", "y = iris.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Standardize Features"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Standarize features\n", "scaler = StandardScaler()\n", "X_std = scaler.fit_transform(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Support Vector Classifier"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create support vector classifier\n", "svc = LinearSVC(C=1.0)\n", "\n", "# Train model\n", "model = svc.fit(X_std, y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create Previously Unseen Observation"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create new observation\n", "new_observation = [[-0.7, 1.1, -1.1 , -1.7]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Predict Class Of Observation"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"scrolled": true}, "outputs": [{"data": {"text/plain": ["array([0])"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["# Predict class of new observation\n", "svc.predict(new_observation)"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 1}